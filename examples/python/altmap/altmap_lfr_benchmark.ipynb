{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LFR benchmark for Altmap vs Map Eq\n",
    "### Compare altmap to map eq using networkx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Using matplotlib backend: Qt5Agg\nPopulating the interactive namespace from numpy and matplotlib\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "%pylab\n",
    "\n",
    "%run helpers.py\n",
    "# loads the following helper functions:\n",
    "# infomap(net_path, altmap=False, additional_args='')\n",
    "# read_tree(tree_path)\n",
    "# plogq(p, q)\n",
    "# plogp(p)\n",
    "# drawNetwork(G, communities)\n",
    "# altmap_cost(G, communities)\n",
    "# create_initfile(G, N_partitions=None, randomized=True)\n",
    "# generate_two_rings(n_ring=10)\n",
    "# \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "from networkx.algorithms.community.community_generators import LFR_benchmark_graph\n",
    "from sklearn.metrics import normalized_mutual_info_score as nmi_score\n",
    "\n",
    "# generate LFR benchmark graph + extract ground truth communities\n",
    "def generate_LFR_benchmark(N = 250, mu = 0.1):\n",
    "    \n",
    "    # LFR params\n",
    "    max_degree = int(0.1*N)\n",
    "    max_community = int(0.1*N)\n",
    "    min_community = int(0.05*N)\n",
    "    average_degree = 10\n",
    "    tau1 = 2.0 # Power law exponent for the degree distribution \n",
    "    tau2 = 1.1 # Power law exponent for the community size distribution\n",
    "\n",
    "    # generate LFR benchmark graph\n",
    "    \n",
    "    G = LFR_benchmark_graph(N, tau1, tau2, mu, average_degree=average_degree, max_degree=max_degree, \n",
    "                            max_community=max_community, min_community=min_community, max_iters=200)\n",
    "    G = nx.convert_node_labels_to_integers(G, first_label=1)\n",
    "    \n",
    "    # extract ground truth communities from networkx graph object\n",
    "    communities_true = {}\n",
    "    num_communities = 0\n",
    "    for n in range(1,N+1):\n",
    "        if n in communities_true:\n",
    "            continue\n",
    "            \n",
    "        num_communities = num_communities + 1\n",
    "        community = G.nodes[n]['community']\n",
    "        node_ids = np.asarray(list(community))\n",
    "        node_ids = node_ids + 1 # have node labels >= 1\n",
    "        communities_true.update(dict.fromkeys(node_ids , num_communities))\n",
    "        \n",
    "    communities_true = OrderedDict(sorted(communities_true.items()))\n",
    "    \n",
    "    return G, communities_true\n",
    "\n",
    "# compute normalized mutual information between two partitions\n",
    "def compute_nmi(communities_true, communities_found):\n",
    "    labels_true = list(communities_true.values())\n",
    "    labels_found = list(communities_found.values())\n",
    "\n",
    "    return nmi_score(labels_true,labels_found, average_method='arithmetic')\n",
    "\n",
    "# LFR Benchmark\n",
    "# num_iterations .. number of benchmarks for each parameter pair (mu, N)\n",
    "def run_benchmark(N_list, mu_list, cost_function = 'altmap', init='std', num_realizations=10):\n",
    "    \n",
    "    if cost_function not in {'altmap', 'mapeq'}:\n",
    "        cost_function = 'altmap'\n",
    "    altmap = (cost_function == 'altmap')\n",
    "        \n",
    "    if init not in {'std', 'random'}:\n",
    "        init = 'std'\n",
    "    \n",
    "    benchmark_mean_nmi = np.zeros((len(mu_list), len(N_list)))\n",
    "    benchmark_variance = np.zeros((len(mu_list), len(N_list)))\n",
    "    for mu_idx, mu in enumerate(mu_list):\n",
    "        for N_idx, N in enumerate(N_list):\n",
    "            nmi_list = []\n",
    "            for realization in range(0, num_realizations):\n",
    "                print(f'Starting benchmark for (N,mu) = ({N},{mu})\\n')\n",
    "                try:\n",
    "                    G, communities_true = generate_LFR_benchmark(N, mu)\n",
    "                except nx.ExceededMaxIterations:\n",
    "                    print(f'No benchmark for (N,mu) = ({N},{mu})\\n')\n",
    "                    continue\n",
    "                num_communities_true = max(communities_true.values()) - min(communities_true.values()) + 1\n",
    "                \n",
    "                nx.write_pajek(G, workspace_path +  filename + '.net')\n",
    "                \n",
    "                if init == 'random':\n",
    "                    communities = create_initfile(G, randomized=True)\n",
    "                    infomap(workspace_path +  filename + '.net', altmap=altmap, additional_args=' --cluster-data ./workspace/init.tree')\n",
    "                else:\n",
    "                    infomap(workspace_path +  filename + '.net', altmap=altmap)\n",
    "                    \n",
    "                communities_found, num_communities_found = read_communities_from_tree_file()\n",
    "                print (f'We found {num_communities_found} communities vs. {num_communities_true} ground truth communities.\\n')\n",
    "                \n",
    "                nmi = compute_nmi(communities_true, communities_found)\n",
    "                nmi_list.append(nmi)\n",
    "                \n",
    "            benchmark_mean_nmi[mu_idx, N_idx] = np.mean(nmi_list)\n",
    "            benchmark_variance[mu_idx, N_idx] = np.var(nmi_list, ddof=1)\n",
    "            #print (f'Normalized mutual information I(.,.) = {nmi}.\\n')\n",
    "            \n",
    "    return benchmark_mean_nmi, benchmark_variance\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% helpers + wrappers\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[482, 1000]\n[0.05       0.12777778 0.20555556 0.28333333 0.36111111 0.43888889\n 0.51666667 0.59444444 0.67222222 0.75      ]\nStarting benchmark for (N,mu) = (482,0.05)\n\n",
      "We found 13 communities vs. 13 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.05)\n\n",
      "No benchmark for (N,mu) = (482,0.05)\n\nStarting benchmark for (N,mu) = (1000,0.05)\n\n",
      "We found 14 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.05)\n\n",
      "We found 14 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.12777777777777777)\n\n",
      "We found 14 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.12777777777777777)\n\n",
      "No benchmark for (N,mu) = (482,0.12777777777777777)\n\nStarting benchmark for (N,mu) = (1000,0.12777777777777777)\n\n",
      "We found 13 communities vs. 13 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.12777777777777777)\n\n",
      "We found 14 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.20555555555555555)\n\n",
      "We found 14 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.20555555555555555)\n\n",
      "We found 14 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.20555555555555555)\n\n",
      "We found 14 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.20555555555555555)\n\n",
      "We found 17 communities vs. 15 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.2833333333333333)\n\n",
      "We found 14 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.2833333333333333)\n\n",
      "We found 14 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.2833333333333333)\n\n",
      "We found 14 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.2833333333333333)\n\n",
      "We found 14 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.3611111111111111)\n\n",
      "We found 15 communities vs. 15 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.3611111111111111)\n\n",
      "We found 15 communities vs. 15 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.3611111111111111)\n\n",
      "We found 23 communities vs. 13 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.3611111111111111)\n\n",
      "We found 22 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.4388888888888889)\n\n",
      "We found 18 communities vs. 15 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.4388888888888889)\n\n",
      "We found 15 communities vs. 15 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.4388888888888889)\n\n",
      "We found 23 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.4388888888888889)\n\n",
      "We found 25 communities vs. 13 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.5166666666666667)\n\n",
      "We found 1 communities vs. 15 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.5166666666666667)\n\n",
      "We found 1 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.5166666666666667)\n\n",
      "We found 41 communities vs. 13 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.5166666666666667)\n\nNo benchmark for (N,mu) = (1000,0.5166666666666667)\n\nStarting benchmark for (N,mu) = (482,0.5944444444444446)\n\n",
      "No benchmark for (N,mu) = (482,0.5944444444444446)\n\nStarting benchmark for (N,mu) = (482,0.5944444444444446)\n\n",
      "We found 1 communities vs. 15 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.5944444444444446)\n\n",
      "We found 1 communities vs. 15 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.5944444444444446)\n\n",
      "We found 38 communities vs. 15 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.6722222222222223)\n\n",
      "We found 1 communities vs. 15 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.6722222222222223)\n\n",
      "We found 1 communities vs. 15 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.6722222222222223)\n\n",
      "We found 1 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.6722222222222223)\n\n",
      "We found 1 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.75)\n\n",
      "We found 1 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (482,0.75)\n\n",
      "We found 1 communities vs. 15 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.75)\n\n",
      "We found 1 communities vs. 14 ground truth communities.\n\nStarting benchmark for (N,mu) = (1000,0.75)\n\n",
      "We found 1 communities vs. 14 ground truth communities.\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/chri/anaconda3/lib/python3.6/site-packages/networkx/readwrite/pajek.py:77: UserWarning: Node attribute community is not processed. Non-string attribute.\n  'Non-string attribute'))\n",
      "/home/chri/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3367: RuntimeWarning: Degrees of freedom <= 0 for slice\n  **kwargs)\n/home/chri/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n  ret = ret.dtype.type(ret / rcount)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#Ns = np.linspace(300,1000, 5, dtype=int)\n",
    "Ns = [482, 1000]\n",
    "mus = np.linspace(0.05, 0.75, 10)\n",
    "\n",
    "print (Ns)\n",
    "print (mus)\n",
    "\n",
    "benchmark_mean_nmi, benchmark_variance = run_benchmark(Ns, mus, num_realizations=2 ,cost_function = 'mapeq', \n",
    "                                                       init='std')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% run benchmarks\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "benchmark_std_dev = np.sqrt(benchmark_variance)\n",
    "mean_benchmark_results = np.mean(benchmark_mean_nmi, axis=1)\n",
    "\n",
    "plt.close('all')\n",
    "fig, axs = plt.subplots(2,1,sharex=True)\n",
    "fig.suptitle('Infomap')\n",
    "\n",
    "axs[0].plot(mus, benchmark_mean_nmi[:,0], label='N=482')\n",
    "axs[0].plot(mus, benchmark_mean_nmi[:,1], label='N=1000')\n",
    "axs[0].plot(mus, mean_benchmark_results, label='mean')\n",
    "axs[0].plot([0.5, 0.5], [0,1])\n",
    "axs[0].grid()\n",
    "axs[0].set_xlabel('Mixing parameter \\mu')\n",
    "axs[0].set_ylabel('NMI')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(mus, benchmark_std_dev[:,0], label='N=482')\n",
    "axs[1].plot(mus, benchmark_std_dev[:,1], label='N=1000')\n",
    "axs[1].grid()\n",
    "axs[1].set_xlabel('Mixing parameter \\mu')\n",
    "axs[1].set_ylabel('Standard deviation')\n",
    "axs[1].legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure()\n",
    "plt.title('Ground Truth Communities')\n",
    "drawNetwork(G, communities_true, labels=False)\n",
    "\n",
    "# \n",
    "# plt.figure()\n",
    "# plt.title('Infomap/Altmap Communities')\n",
    "# drawNetwork(G, communities_found, labels=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}