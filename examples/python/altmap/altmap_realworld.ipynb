{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Altmap Experiments\n",
    "### Compare altmap to map eq using networkx on realworld networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "from clusim.clustering import Clustering\n",
    "\n",
    "from altmap.altmap_helpers.general import *\n",
    "\n",
    "# show plots in separate window\n",
    "%pylab\n",
    "\n",
    "# init rc params\n",
    "init_plt_params()\n",
    "\n",
    "def num_nodes_in_multiple_comms(comm_list):\n",
    "    nodes = sorted(list(itertools.chain(*comm_list)))\n",
    "    num_multiple_comms = 0\n",
    "    last_node = -1\n",
    "    already_counted = False\n",
    "    for node in nodes:\n",
    "        if last_node != node:\n",
    "            last_node = node\n",
    "            already_counted = False\n",
    "        elif not already_counted:\n",
    "            num_multiple_comms += 1\n",
    "            already_counted = True\n",
    "    \n",
    "    return num_multiple_comms\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% imports\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "There are 1134890 nodes in the full network\n",
      "There are 2987624 edges in the full network\n",
      "There are 5000 admissible ground truth communities.\n",
      "The minimun community size is 2.\n",
      "The mean community size is 14.5918.\n",
      "The maximum community size is 2217.\n",
      "There are 39841 nodes in the reduced network\n",
      "There are 224235 edges in the reduced network\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# dataset = 'dblp' # citation network\n",
    "dataset = 'youtube'\n",
    "# dataset = 'amazon'\n",
    "\n",
    "# load network\n",
    "path = './realworld/com-' + dataset + '.ungraph.txt'\n",
    "G = nx.read_adjlist(path, create_using=nx.Graph, nodetype=int)\n",
    "\n",
    "print(f'There are {len(G.nodes())} nodes in the full network')\n",
    "print(f'There are {len(G.edges())} edges in the full network')\n",
    "\n",
    "# load groundtruth comms\n",
    "path = './realworld/com-' + dataset + '.top5000.cmty.txt'\n",
    "with open(path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "comm_list = [list(map(int, line.strip().split('\\t'))) for line in lines]\n",
    "comm_sizes = list(map(len, comm_list))\n",
    "\n",
    "# take only communities with at least x nodes\n",
    "min_comm_size = 1\n",
    "comm_true_list = [comm for comm in comm_list if len(comm) >= min_comm_size]\n",
    "comm_true_sizes = list(map(len, comm_true_list))\n",
    "num_comm_true = len(comm_true_list)\n",
    "\n",
    "print(f'There are {num_comm_true} admissible ground truth communities.')\n",
    "print(f'The minimun community size is {np.min(comm_true_sizes)}.')\n",
    "print(f'The mean community size is {np.mean(comm_true_sizes)}.')\n",
    "print(f'The maximum community size is {np.max(comm_true_sizes)}.')\n",
    "\n",
    "# extract reduced graph\n",
    "node_ids = list(itertools.chain(*comm_true_list))\n",
    "unique_node_ids = set(np.unique(node_ids)) # unique node ids part of some top community\n",
    "G_reduced = G.subgraph(unique_node_ids)\n",
    "\n",
    "print(f'There are {len(G_reduced.nodes())} nodes in the reduced network')\n",
    "print(f'There are {len(G_reduced.edges())} edges in the reduced network')\n",
    "\n",
    "# relabelling necessary for the computation of the omega index\n",
    "nodes_relabelling_map = dict(zip(sorted(unique_node_ids),  range(len(unique_node_ids))))\n",
    "\n",
    "# assemble ground truth clusim clustering\n",
    "comm_list_relabelled = [[nodes_relabelling_map[node] for node in comm] for comm in comm_true_list]\n",
    "comm_labels = list(range(1, num_comm_true + 1))\n",
    "clu2elm = dict(zip(comm_labels, comm_list_relabelled))\n",
    "clustering_true = Clustering(clu2elm_dict=clu2elm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% load dataset\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Number of nodes that are part of multiple communities (reduced network): 12547\n",
      "Fraction of nodes that are part of multiple communities (reduced network): 0.3149268341658091\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "num_multiple = num_nodes_in_multiple_comms(comm_true_list)\n",
    "print (f'Number of nodes that are part of multiple communities (reduced network): {num_multiple}')\n",
    "print (f'Fraction of nodes that are part of multiple communities (reduced network): {num_multiple / len(G_reduced.nodes())}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% count number of nodes that are part of multiple communities\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Testing Infomap...\n",
      "Found 2491 communities on reduced network.\n",
      "Achieved RENDC is -0.5018.\n",
      "Testing Altmap...\n",
      "Found 3029 communities on reduced network.\n",
      "Achieved RENDC is -0.3942.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "reduced_network = True # detect communities from reduced graph\n",
    "G_test = G_reduced if reduced_network else G\n",
    "\n",
    "# run community detection for infomap\n",
    "print('Testing Infomap...')\n",
    "communities_found, num_communities_found,_,_ = infomap(G_test, altmap=False)\n",
    "\n",
    "# remove nodes from found communities that are not in ground truth comms\n",
    "if not reduced_network:\n",
    "    communities_found = OrderedDict((node,communities_found[node]) for node in sorted(unique_node_ids))\n",
    "    num_communities_found = get_num_communities(communities_found)\n",
    "\n",
    "communities_found_infomap = communities_found\n",
    "print (f'Found {num_communities_found} communities on ' + ('reduced' if reduced_network else 'full') + ' network.')\n",
    "print (f'Achieved RENDC is {num_communities_found/5000.0 - 1}.')\n",
    "\n",
    "\n",
    "# # run community detection for altmap\n",
    "print('Testing Altmap...')\n",
    "communities_found, num_communities_found,_,_ = infomap(G_test, altmap=True, update_inputfile=False)\n",
    "\n",
    "# remove nodes from found communities that are not in ground truth comms\n",
    "if not reduced_network:\n",
    "    communities_found = OrderedDict((node,communities_found[node]) for node in sorted(unique_node_ids))\n",
    "    num_communities_found = get_num_communities(communities_found)\n",
    "\n",
    "communities_found_altmap = communities_found\n",
    "print (f'Found {num_communities_found} communities on ' + ('reduced' if reduced_network else 'full') + ' network.')\n",
    "print (f'Achieved RENDC is {num_communities_found/5000.0 - 1}.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% find communities\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Computing scores for Infomap...\n",
      "Computing metric 1...\n",
      "Computing metric 2...\n",
      "Infomap scores are: onmi = 0.5193674411154029, omega_idx = 0.18962374672062143.\n",
      "Computing scores for Altmap...\n",
      "Computing metric 1...\n",
      "Computing metric 2...\n",
      "Infomap scores are: onmi = 0.42968765144687615, omega_idx = 0.21373415392993803.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from clusim.sim import onmi\n",
    "from clusim.sim import omega_index\n",
    "from clusim.clusimelement import element_sim # very memory intense\n",
    "\n",
    "def evaluate_clusterings(communities_found, metrics):\n",
    "    # assemble detected clustering\n",
    "    elm2clu = dict([(nodes_relabelling_map[node], [label]) for node, label in communities_found.items()])\n",
    "    clustering_found= Clustering(elm2clu_dict=elm2clu)\n",
    "    \n",
    "    scores = []\n",
    "    for i, metric in enumerate(metrics):\n",
    "        print (f'Computing metric {i+1}...')\n",
    "        scores.append(metric(clustering_found, clustering_true))\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "metrics = (onmi, omega_index)\n",
    "\n",
    "print ('Computing scores for Infomap...')\n",
    "scores = evaluate_clusterings(communities_found_infomap, metrics)\n",
    "print (f'Infomap scores are: onmi = {scores[0]}, omega_idx = {scores[1]}.')\n",
    "\n",
    "print ('Computing scores for Altmap...')\n",
    "scores = evaluate_clusterings(communities_found_altmap, metrics)\n",
    "print (f'Altmap scores are: onmi = {scores[0]}, omega_idx = {scores[1]}.')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% evaluate results\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}