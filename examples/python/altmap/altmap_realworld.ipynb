{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Altmap Experiments\n",
    "### Compare altmap to map eq using networkx on realworld networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "from clusim.clustering import Clustering\n",
    "\n",
    "from altmap.altmap_helpers.general import *\n",
    "\n",
    "# show plots in separate window\n",
    "%pylab\n",
    "\n",
    "# init rc params\n",
    "init_plt_params()\n",
    "\n",
    "def num_nodes_in_multiple_comms(comm_list):\n",
    "    nodes = sorted(list(itertools.chain(*comm_list)))\n",
    "    num_multiple_comms = 0\n",
    "    last_node = -1\n",
    "    already_counted = False\n",
    "    for node in nodes:\n",
    "        if last_node != node:\n",
    "            last_node = node\n",
    "            already_counted = False\n",
    "        elif not already_counted:\n",
    "            num_multiple_comms += 1\n",
    "            already_counted = True\n",
    "    \n",
    "    return num_multiple_comms\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% imports\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "There are 5000 admissible ground truth communities.\n",
      "The minimun community size is 3.\n",
      "The mean community size is 215.7152.\n",
      "The maximum community size is 4785.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "dataset = 'dblp' # citation network\n",
    "# dataset = 'youtube'\n",
    "# dataset = 'amazon'\n",
    "# dataset = 'lj'\n",
    "# dataset = 'orkut'\n",
    "\n",
    "# load groundtruth comms\n",
    "path = './realworld/com-' + dataset + '.top5000.cmty.txt'\n",
    "comm_list = []\n",
    "with open(path, 'r') as file:\n",
    "    for line in file:\n",
    "        comm_list.append(list(map(int, line.strip().split('\\t')))) \n",
    "        \n",
    "comm_sizes = list(map(len, comm_list))\n",
    "\n",
    "# take only communities with at least x nodes\n",
    "min_comm_size = 1\n",
    "comm_true_list = [comm for comm in comm_list if len(comm) >= min_comm_size]\n",
    "comm_true_sizes = list(map(len, comm_true_list))\n",
    "num_comm_true = len(comm_true_list)\n",
    "\n",
    "# extract unique node ids\n",
    "node_ids = list(itertools.chain(*comm_true_list))\n",
    "unique_node_ids = set(np.unique(node_ids)) # unique node ids part of some top community\n",
    "\n",
    "print(f'There are {num_comm_true} admissible ground truth communities.')\n",
    "print(f'The minimun community size is {np.min(comm_true_sizes)}.')\n",
    "print(f'The mean community size is {np.mean(comm_true_sizes)}.')\n",
    "print(f'The maximum community size is {np.max(comm_true_sizes)}.')\n",
    "\n",
    "# relabelling necessary for the computation of the omega index\n",
    "nodes_relabelling_map = dict(zip(sorted(unique_node_ids),  range(len(unique_node_ids))))\n",
    "\n",
    "# assemble ground truth clusim clustering\n",
    "comm_list_relabelled = [[nodes_relabelling_map[node] for node in comm] for comm in comm_true_list]\n",
    "comm_labels = list(range(1, num_comm_true + 1))\n",
    "clu2elm = dict(zip(comm_labels, comm_list_relabelled))\n",
    "clustering_true = Clustering(clu2elm_dict=clu2elm)\n",
    "\n",
    "# load network\n",
    "path = './realworld/com-' + dataset + '.ungraph.txt'\n",
    "# G = nx.read_adjlist(path, create_using=nx.Graph, nodetype=int)\n",
    "\n",
    "G = nx.Graph()\n",
    "with open(path, 'r') as file:\n",
    "    for line in file:\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        \n",
    "        node1, node2 = tuple(map(int, line.strip().split('\\t')))\n",
    "        if node1 in unique_node_ids and node2 in unique_node_ids:\n",
    "            G.add_edge(node1, node2) \n",
    "\n",
    "print(f'There are {len(G.nodes())} nodes in the reduced network')\n",
    "print(f'There are {len(G.edges())} edges in the reduced network')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% load dataset\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Number of nodes that are part of multiple communities (reduced network): 31450\n",
      "Fraction of nodes that are part of multiple communities (reduced network): 0.37246263530637863\n",
      "Average clustering coefficient (reduced network): 0.764008212007451\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "num_multiple = num_nodes_in_multiple_comms(comm_true_list)\n",
    "print (f'Number of nodes that are part of multiple communities (reduced network): {num_multiple}')\n",
    "print (f'Fraction of nodes that are part of multiple communities (reduced network): {num_multiple / len(G.nodes())}')\n",
    "\n",
    "c = nx.average_clustering(G)\n",
    "print (f'Average clustering coefficient (reduced network): {c}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% count number of nodes that are part of multiple communities\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Testing Infomap...\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# run community detection for infomap\n",
    "print('Testing Infomap...')\n",
    "communities_found_infomap, num_communities_found,_,_ = infomap(G, altmap=False)\n",
    "\n",
    "print (f'Found {num_communities_found} communities on the reduced network.')\n",
    "print (f'Achieved RENDC is {num_communities_found/5000.0 - 1}.')\n",
    "\n",
    "# run community detection for altmap\n",
    "print('Testing Altmap...')\n",
    "communities_found_altmap, num_communities_found,_,_ = infomap(G, altmap=True, update_inputfile=False)\n",
    "\n",
    "print (f'Found {num_communities_found} communities on the reduced network.')\n",
    "print (f'Achieved RENDC is {num_communities_found/5000.0 - 1}.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% find communities\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Computing scores for Infomap...\n",
      "Computing metric 1...\n",
      "Computing metric 2...\n",
      "Infomap scores are: onmi = 0.8754197648885511, omega_idx = 0.6010862039967505.\n",
      "Computing scores for Altmap...\n",
      "Computing metric 1...\n",
      "Computing metric 2...\n",
      "Altmap scores are: onmi = 0.879330724043965, omega_idx = 0.6611350373008688.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from clusim.sim import onmi\n",
    "from clusim.sim import omega_index\n",
    "from clusim.clusimelement import element_sim # very memory intense\n",
    "\n",
    "def evaluate_clusterings(communities_found, metrics):\n",
    "    # assemble detected clustering\n",
    "    elm2clu = dict([(nodes_relabelling_map[node], [label]) for node, label in communities_found.items()])\n",
    "    clustering_found= Clustering(elm2clu_dict=elm2clu)\n",
    "    \n",
    "    scores = []\n",
    "    for i, metric in enumerate(metrics):\n",
    "        print (f'Computing metric {i+1}...')\n",
    "        scores.append(metric(clustering_found, clustering_true))\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "metrics = (onmi, omega_index)\n",
    "\n",
    "print ('Computing scores for Infomap...')\n",
    "scores = evaluate_clusterings(communities_found_infomap, metrics)\n",
    "print (f'Infomap scores are: onmi = {scores[0]}, omega_idx = {scores[1]}.')\n",
    "\n",
    "print ('Computing scores for Altmap...')\n",
    "scores = evaluate_clusterings(communities_found_altmap, metrics)\n",
    "print (f'Altmap scores are: onmi = {scores[0]}, omega_idx = {scores[1]}.')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% evaluate results\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}